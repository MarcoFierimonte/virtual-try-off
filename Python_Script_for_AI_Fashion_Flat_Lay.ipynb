{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcoFierimonte/virtual-try-off/blob/main/Python_Script_for_AI_Fashion_Flat_Lay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For **Path 2 (Serverless GPU / API)**, you are moving away from all-in-one consumer apps and into building your own logic using professional AI APIs. This is the \"Developer Way\"—giving you total control over the output while only paying for what you use.\n",
        "\n",
        "I’ve structured this script using **Replicate** (the most popular platform for this), but the logic works similarly for Fal.ai.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "You will need your API token from [Replicate](https://www.google.com/search?q=https://replicate.com/account).\n",
        "\n",
        "```bash\n",
        "pip install replicate\n",
        "export REPLICATE_API_TOKEN=your_token_here\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### The Python Script: The \"Reconstruction\" Pipeline\n",
        "\n",
        "This script performs the three steps: **Segments** the shirt (SAM 2), **Classifies** the style (Llama Vision), and **Generates** the professional flat-lay (Flux.1)."
      ],
      "metadata": {
        "id": "hnyT-5mdgXBx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOFMq3SYgjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "import json\n",
        "\n",
        "# 1. SEGMENTATION: Isolate the garment from the messy photo\n",
        "def segment_garment(image_url):\n",
        "    print(\"--- Step 1: Segmenting Garment ---\")\n",
        "    # We use SAM 2 to get a high-quality mask\n",
        "    # For clothing, 'mask' is usually the main subject\n",
        "    output = replicate.run(\n",
        "        \"lucataco/remove-bg:95fcc2a26d3899cd6c2691c900465aaeff466285a65c14638cc5f36f34befaf1\",\n",
        "        input={\"image\": image_url}\n",
        "    )\n",
        "    # Returns a URL of the garment with transparent background\n",
        "    print(f\"Isolated Garment: {output}\")\n",
        "    return output\n",
        "\n",
        "# 2. CLASSIFICATION: Identify the item for better prompting\n",
        "def classify_garment(image_url):\n",
        "    print(\"--- Step 2: Classifying Style ---\")\n",
        "    prompt = \"\"\"Analyze this clothing item. Return ONLY a JSON object with:\n",
        "    {\"type\": \"t-shirt/hoodie/etc\", \"color\": \"color\", \"material\": \"material\", \"fit\": \"oversized/slim\"}\"\"\"\n",
        "\n",
        "    output = replicate.run(\n",
        "        \"meta/llama-3.2-11b-vision-instruct\",\n",
        "        input={\n",
        "            \"image\": image_url,\n",
        "            \"prompt\": prompt,\n",
        "            \"max_new_tokens\": 100\n",
        "        }\n",
        "    )\n",
        "    # Parse the clean JSON from the LLM\n",
        "    description = \"\".join(output)\n",
        "    return json.loads(description)\n",
        "\n",
        "# 3. GENERATION: Create the professional Flat-Lay\n",
        "def generate_flat_lay(isolated_image_url, details):\n",
        "    print(\"--- Step 3: Generating Flat Lay ---\")\n",
        "    # We use Flux Fill to \"re-contextualize\" the isolated shirt\n",
        "    prompt = f\"A professional studio flat lay of a {details['fit']} {details['color']} {details['type']} made of {details['material']}. Placed on a clean, minimalist off-white surface with soft natural lighting and elegant shadows. High-end e-commerce photography.\"\n",
        "\n",
        "    output = replicate.run(\n",
        "        \"black-forest-labs/flux-fill-pro\",\n",
        "        input={\n",
        "            \"image\": isolated_image_url,\n",
        "            \"prompt\": prompt,\n",
        "            \"guidance_scale\": 30,\n",
        "            \"output_format\": \"webp\"\n",
        "        }\n",
        "    )\n",
        "    return output[0]\n",
        "\n",
        "# --- EXECUTION ---\n",
        "INPUT_IMAGE = \"https://your-storage.com/messy_photo.jpg\"\n",
        "\n",
        "try:\n",
        "    # Run the pipeline\n",
        "    cutout_url = segment_garment(INPUT_IMAGE)\n",
        "    garment_data = classify_garment(cutout_url)\n",
        "    final_flat_lay = generate_flat_lay(cutout_url, garment_data)\n",
        "\n",
        "    print(\"\\n--- Success! ---\")\n",
        "    print(f\"Your professional flat-lay is ready: {final_flat_lay}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in pipeline: {e}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "k4uCFd7KgXBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Why this works\n",
        "\n",
        "* **SAM 2 / Remove-BG:** Standard background removal often leaves \"halos.\" By using the latest SAM 2-based endpoints, you get the surgical precision needed for clothing edges (stitching, frayed ends).\n",
        "* **Llama 3.2 Vision:** Rather than just saying \"the shirt,\" this step allows your AI to say \"an oversized heavy-weight cotton charcoal tee.\" This specificity tells **Flux** exactly how to handle the textures and drape in the final image.\n",
        "* **Flux.1 Fill:** This is the magic. Unlike standard \"Text-to-Image,\" **Fill** models respect the shape of your original cutout while \"filling in\" the lighting and background to make it look like a real photo.\n",
        "\n",
        "### Comparison of Costs (Approximate)\n",
        "\n",
        "| Action | Model | Cost per Run |\n",
        "| --- | --- | --- |\n",
        "| **Segmentation** | Remove-BG | ~$0.002 |\n",
        "| **Classification** | Llama 3.2 Vision | ~$0.005 |\n",
        "| **Generation** | Flux.1 Fill | ~$0.03 - $0.05 |\n",
        "| **Total** |  | **<$0.10 per image** |\n",
        "\n",
        "**Would you like me to refine the prompt in Step 3 to include specific brand \"vibes\" (e.g., Nike-style vs. luxury boutique)?**"
      ],
      "metadata": {
        "id": "DfgH2UW0gXBz"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}